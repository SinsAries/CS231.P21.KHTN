{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "L-cMsxUmO0bH"
      },
      "outputs": [],
      "source": [
        "from __future__ import print_function\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D\n",
        "import os\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import seaborn as sns\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import itertools\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "mAgP5hjNO-JP"
      },
      "outputs": [],
      "source": [
        "batch_size = 32  # The default batch size of keras.\n",
        "num_classes = 10  # Number of class for the dataset\n",
        "epochs = 100\n",
        "data_augmentation = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "2u7rUoYwPCj3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d6eabd40-a677-429b-a774-a2dbaef98171"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_train shape: (50000, 32, 32, 3)\n",
            "y_train shape: (50000, 1)\n",
            "50000 train samples\n",
            "10000 test samples\n"
          ]
        }
      ],
      "source": [
        "# The data, split between train and test sets:\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "print('x_train shape:', x_train.shape)\n",
        "print('y_train shape:', y_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "PAln9kOdPHhO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "outputId": "4510db2c-7bff-44c2-cc4c-3166af7f129e"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1500x500 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "fig, axs = plt.subplots(1,2,figsize=(15,5))\n",
        "# Count plot for training set\n",
        "sns.countplot(y_train.ravel(), ax=axs[0])\n",
        "axs[0].set_title('Distribution of training data')\n",
        "axs[0].set_xlabel('Classes')\n",
        "# Count plot for testing set\n",
        "sns.countplot(y_test.ravel(), ax=axs[1])\n",
        "axs[1].set_title('Distribution of Testing data')\n",
        "axs[1].set_xlabel('Classes')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "NIev7TXRPHgf"
      },
      "outputs": [],
      "source": [
        "# Normalize the data. Before we need to connvert data type to float for computation.\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "NeeCR-MCPLZY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 797
        },
        "outputId": "7dbc01b9-537c-4db5-c76b-9000eeb4f94c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m896\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ activation_6 (\u001b[38;5;33mActivation\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_5 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │         \u001b[38;5;34m9,248\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ activation_7 (\u001b[38;5;33mActivation\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_6 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m18,496\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ activation_8 (\u001b[38;5;33mActivation\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_7 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m36,928\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ activation_9 (\u001b[38;5;33mActivation\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_3 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten_1 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2304\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │     \u001b[38;5;34m1,180,160\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ activation_10 (\u001b[38;5;33mActivation\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_5 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │         \u001b[38;5;34m5,130\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ activation_11 (\u001b[38;5;33mActivation\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ activation_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">9,248</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ activation_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ activation_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ activation_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2304</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,180,160</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ activation_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">5,130</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ activation_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,250,858\u001b[0m (4.77 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,250,858</span> (4.77 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,250,858\u001b[0m (4.77 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,250,858</span> (4.77 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "#define the convnet\n",
        "model = Sequential()\n",
        "# CONV => RELU => CONV => RELU => POOL => DROPOUT\n",
        "model.add(Conv2D(32, (3, 3), padding='same',input_shape=x_train.shape[1:]))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(32, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "# CONV => RELU => CONV => RELU => POOL => DROPOUT\n",
        "model.add(Conv2D(64, (3, 3), padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(64, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "# FLATTERN => DENSE => RELU => DROPOUT\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "# a softmax classifier\n",
        "model.add(Dense(num_classes))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "Fuhs617SPMXC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c0a1e682-99c2-4c2f-b72c-da93ace273f9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/optimizers/base_optimizer.py:86: UserWarning: Argument `decay` is no longer supported and will be ignored.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# initiate RMSprop optimizer\n",
        "opt = tf.keras.optimizers.RMSprop(learning_rate=0.0001, decay=1e-6)\n",
        "\n",
        "# Let's train the model using RMSprop\n",
        "model.compile(loss='sparse_categorical_crossentropy',\n",
        "              optimizer=opt,\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UnBnYADXPMWT",
        "outputId": "838c43b0-b729-4b1e-aa07-d9786d76e1de"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using real-time data augmentation.\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 22ms/step - accuracy: 0.2310 - loss: 2.0532 - val_accuracy: 0.4360 - val_loss: 1.5638\n",
            "Epoch 2/100\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 19ms/step - accuracy: 0.4021 - loss: 1.6269 - val_accuracy: 0.4826 - val_loss: 1.4484\n",
            "Epoch 3/100\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 20ms/step - accuracy: 0.4530 - loss: 1.4980 - val_accuracy: 0.5214 - val_loss: 1.3131\n",
            "Epoch 4/100\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 19ms/step - accuracy: 0.4899 - loss: 1.4129 - val_accuracy: 0.5221 - val_loss: 1.3462\n",
            "Epoch 5/100\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 20ms/step - accuracy: 0.5123 - loss: 1.3589 - val_accuracy: 0.5710 - val_loss: 1.2119\n",
            "Epoch 6/100\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 19ms/step - accuracy: 0.5343 - loss: 1.3012 - val_accuracy: 0.5976 - val_loss: 1.1533\n",
            "Epoch 7/100\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 20ms/step - accuracy: 0.5570 - loss: 1.2452 - val_accuracy: 0.6094 - val_loss: 1.0986\n",
            "Epoch 8/100\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 19ms/step - accuracy: 0.5765 - loss: 1.2056 - val_accuracy: 0.6312 - val_loss: 1.0404\n",
            "Epoch 9/100\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 20ms/step - accuracy: 0.5818 - loss: 1.1760 - val_accuracy: 0.6375 - val_loss: 1.0293\n",
            "Epoch 10/100\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 20ms/step - accuracy: 0.5988 - loss: 1.1317 - val_accuracy: 0.6411 - val_loss: 1.0224\n",
            "Epoch 11/100\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 20ms/step - accuracy: 0.6099 - loss: 1.1065 - val_accuracy: 0.6567 - val_loss: 0.9820\n",
            "Epoch 12/100\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 19ms/step - accuracy: 0.6216 - loss: 1.0719 - val_accuracy: 0.6779 - val_loss: 0.9080\n",
            "Epoch 13/100\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 19ms/step - accuracy: 0.6280 - loss: 1.0508 - val_accuracy: 0.6817 - val_loss: 0.9053\n",
            "Epoch 14/100\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 19ms/step - accuracy: 0.6399 - loss: 1.0284 - val_accuracy: 0.6863 - val_loss: 0.8850\n",
            "Epoch 15/100\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 20ms/step - accuracy: 0.6476 - loss: 1.0041 - val_accuracy: 0.6902 - val_loss: 0.8816\n",
            "Epoch 16/100\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 20ms/step - accuracy: 0.6533 - loss: 0.9885 - val_accuracy: 0.7134 - val_loss: 0.8186\n",
            "Epoch 17/100\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 20ms/step - accuracy: 0.6602 - loss: 0.9685 - val_accuracy: 0.7019 - val_loss: 0.8786\n",
            "Epoch 18/100\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 20ms/step - accuracy: 0.6681 - loss: 0.9549 - val_accuracy: 0.7211 - val_loss: 0.8150\n",
            "Epoch 19/100\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 20ms/step - accuracy: 0.6725 - loss: 0.9367 - val_accuracy: 0.6978 - val_loss: 0.8781\n",
            "Epoch 20/100\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 19ms/step - accuracy: 0.6715 - loss: 0.9295 - val_accuracy: 0.7038 - val_loss: 0.8447\n",
            "Epoch 21/100\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 20ms/step - accuracy: 0.6788 - loss: 0.9134 - val_accuracy: 0.7275 - val_loss: 0.7886\n",
            "Epoch 22/100\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 19ms/step - accuracy: 0.6863 - loss: 0.8970 - val_accuracy: 0.7121 - val_loss: 0.8285\n",
            "Epoch 23/100\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 19ms/step - accuracy: 0.6890 - loss: 0.8946 - val_accuracy: 0.7298 - val_loss: 0.7803\n",
            "Epoch 24/100\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 19ms/step - accuracy: 0.6942 - loss: 0.8871 - val_accuracy: 0.7352 - val_loss: 0.7647\n",
            "Epoch 25/100\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 20ms/step - accuracy: 0.6974 - loss: 0.8751 - val_accuracy: 0.7413 - val_loss: 0.7538\n",
            "Epoch 26/100\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 20ms/step - accuracy: 0.7001 - loss: 0.8710 - val_accuracy: 0.7309 - val_loss: 0.7836\n",
            "Epoch 27/100\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 20ms/step - accuracy: 0.7035 - loss: 0.8584 - val_accuracy: 0.7285 - val_loss: 0.7757\n",
            "Epoch 28/100\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 20ms/step - accuracy: 0.7037 - loss: 0.8558 - val_accuracy: 0.7446 - val_loss: 0.7506\n",
            "Epoch 29/100\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 20ms/step - accuracy: 0.7079 - loss: 0.8518 - val_accuracy: 0.7502 - val_loss: 0.7335\n",
            "Epoch 30/100\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 19ms/step - accuracy: 0.7094 - loss: 0.8475 - val_accuracy: 0.7488 - val_loss: 0.7342\n",
            "Epoch 31/100\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 20ms/step - accuracy: 0.7103 - loss: 0.8434 - val_accuracy: 0.7547 - val_loss: 0.7176\n",
            "Epoch 32/100\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 20ms/step - accuracy: 0.7122 - loss: 0.8336 - val_accuracy: 0.7627 - val_loss: 0.6999\n",
            "Epoch 33/100\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 20ms/step - accuracy: 0.7139 - loss: 0.8259 - val_accuracy: 0.7529 - val_loss: 0.7206\n",
            "Epoch 34/100\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 19ms/step - accuracy: 0.7209 - loss: 0.8200 - val_accuracy: 0.7364 - val_loss: 0.7846\n",
            "Epoch 35/100\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 20ms/step - accuracy: 0.7178 - loss: 0.8254 - val_accuracy: 0.7730 - val_loss: 0.6765\n",
            "Epoch 36/100\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 20ms/step - accuracy: 0.7214 - loss: 0.8109 - val_accuracy: 0.7606 - val_loss: 0.7113\n",
            "Epoch 37/100\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 20ms/step - accuracy: 0.7206 - loss: 0.8075 - val_accuracy: 0.7553 - val_loss: 0.7241\n",
            "Epoch 38/100\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 20ms/step - accuracy: 0.7280 - loss: 0.8030 - val_accuracy: 0.7592 - val_loss: 0.7071\n",
            "Epoch 39/100\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 20ms/step - accuracy: 0.7266 - loss: 0.7967 - val_accuracy: 0.7713 - val_loss: 0.6790\n",
            "Epoch 40/100\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 20ms/step - accuracy: 0.7259 - loss: 0.7951 - val_accuracy: 0.7604 - val_loss: 0.7000\n",
            "Epoch 41/100\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 20ms/step - accuracy: 0.7285 - loss: 0.7963 - val_accuracy: 0.7651 - val_loss: 0.6921\n",
            "Epoch 42/100\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 20ms/step - accuracy: 0.7291 - loss: 0.7971 - val_accuracy: 0.7661 - val_loss: 0.6829\n",
            "Epoch 43/100\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 20ms/step - accuracy: 0.7307 - loss: 0.7869 - val_accuracy: 0.7517 - val_loss: 0.7156\n",
            "Epoch 44/100\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 19ms/step - accuracy: 0.7369 - loss: 0.7741 - val_accuracy: 0.7627 - val_loss: 0.6956\n",
            "Epoch 45/100\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 20ms/step - accuracy: 0.7364 - loss: 0.7775 - val_accuracy: 0.7661 - val_loss: 0.6904\n",
            "Epoch 46/100\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 20ms/step - accuracy: 0.7314 - loss: 0.7836 - val_accuracy: 0.7594 - val_loss: 0.7056\n",
            "Epoch 47/100\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 20ms/step - accuracy: 0.7358 - loss: 0.7708 - val_accuracy: 0.7685 - val_loss: 0.6765\n",
            "Epoch 48/100\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 20ms/step - accuracy: 0.7345 - loss: 0.7719 - val_accuracy: 0.7750 - val_loss: 0.6667\n",
            "Epoch 49/100\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 19ms/step - accuracy: 0.7375 - loss: 0.7722 - val_accuracy: 0.7605 - val_loss: 0.6946\n",
            "Epoch 50/100\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 20ms/step - accuracy: 0.7369 - loss: 0.7696 - val_accuracy: 0.7667 - val_loss: 0.6882\n",
            "Epoch 51/100\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 20ms/step - accuracy: 0.7407 - loss: 0.7624 - val_accuracy: 0.7605 - val_loss: 0.7113\n",
            "Epoch 52/100\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 20ms/step - accuracy: 0.7381 - loss: 0.7666 - val_accuracy: 0.7625 - val_loss: 0.7020\n",
            "Epoch 53/100\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 20ms/step - accuracy: 0.7370 - loss: 0.7680 - val_accuracy: 0.7782 - val_loss: 0.6502\n",
            "Epoch 54/100\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 20ms/step - accuracy: 0.7392 - loss: 0.7631 - val_accuracy: 0.7549 - val_loss: 0.7124\n",
            "Epoch 55/100\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 20ms/step - accuracy: 0.7428 - loss: 0.7595 - val_accuracy: 0.7739 - val_loss: 0.6716\n",
            "Epoch 56/100\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 20ms/step - accuracy: 0.7435 - loss: 0.7592 - val_accuracy: 0.7734 - val_loss: 0.6690\n",
            "Epoch 57/100\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 20ms/step - accuracy: 0.7438 - loss: 0.7498 - val_accuracy: 0.7788 - val_loss: 0.6510\n",
            "Epoch 58/100\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 20ms/step - accuracy: 0.7424 - loss: 0.7599 - val_accuracy: 0.7804 - val_loss: 0.6489\n",
            "Epoch 59/100\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 20ms/step - accuracy: 0.7488 - loss: 0.7437 - val_accuracy: 0.7787 - val_loss: 0.6572\n",
            "Epoch 60/100\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 20ms/step - accuracy: 0.7481 - loss: 0.7484 - val_accuracy: 0.7671 - val_loss: 0.6795\n",
            "Epoch 61/100\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 20ms/step - accuracy: 0.7477 - loss: 0.7428 - val_accuracy: 0.7750 - val_loss: 0.6547\n",
            "Epoch 62/100\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 20ms/step - accuracy: 0.7487 - loss: 0.7408 - val_accuracy: 0.7509 - val_loss: 0.7451\n",
            "Epoch 63/100\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 19ms/step - accuracy: 0.7460 - loss: 0.7453 - val_accuracy: 0.7817 - val_loss: 0.6547\n",
            "Epoch 64/100\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 20ms/step - accuracy: 0.7508 - loss: 0.7451 - val_accuracy: 0.7779 - val_loss: 0.6597\n",
            "Epoch 65/100\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 20ms/step - accuracy: 0.7442 - loss: 0.7534 - val_accuracy: 0.7874 - val_loss: 0.6243\n",
            "Epoch 66/100\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 20ms/step - accuracy: 0.7515 - loss: 0.7323 - val_accuracy: 0.7671 - val_loss: 0.6786\n",
            "Epoch 67/100\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 20ms/step - accuracy: 0.7520 - loss: 0.7297 - val_accuracy: 0.7659 - val_loss: 0.6871\n",
            "Epoch 68/100\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 20ms/step - accuracy: 0.7505 - loss: 0.7355 - val_accuracy: 0.7862 - val_loss: 0.6290\n",
            "Epoch 69/100\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 20ms/step - accuracy: 0.7495 - loss: 0.7429 - val_accuracy: 0.7872 - val_loss: 0.6319\n",
            "Epoch 70/100\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 20ms/step - accuracy: 0.7530 - loss: 0.7365 - val_accuracy: 0.7746 - val_loss: 0.6625\n",
            "Epoch 71/100\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 20ms/step - accuracy: 0.7519 - loss: 0.7313 - val_accuracy: 0.7781 - val_loss: 0.6560\n",
            "Epoch 72/100\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 19ms/step - accuracy: 0.7547 - loss: 0.7277 - val_accuracy: 0.7889 - val_loss: 0.6346\n",
            "Epoch 73/100\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 20ms/step - accuracy: 0.7504 - loss: 0.7324 - val_accuracy: 0.7822 - val_loss: 0.6454\n",
            "Epoch 74/100\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 20ms/step - accuracy: 0.7535 - loss: 0.7261 - val_accuracy: 0.7604 - val_loss: 0.7005\n",
            "Epoch 75/100\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 20ms/step - accuracy: 0.7530 - loss: 0.7276 - val_accuracy: 0.7872 - val_loss: 0.6334\n",
            "Epoch 76/100\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 20ms/step - accuracy: 0.7525 - loss: 0.7276 - val_accuracy: 0.7806 - val_loss: 0.6438\n",
            "Epoch 77/100\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 20ms/step - accuracy: 0.7542 - loss: 0.7323 - val_accuracy: 0.7654 - val_loss: 0.7006\n",
            "Epoch 78/100\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 20ms/step - accuracy: 0.7603 - loss: 0.7184 - val_accuracy: 0.7595 - val_loss: 0.7104\n",
            "Epoch 79/100\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 20ms/step - accuracy: 0.7548 - loss: 0.7251 - val_accuracy: 0.7849 - val_loss: 0.6554\n",
            "Epoch 80/100\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 20ms/step - accuracy: 0.7532 - loss: 0.7310 - val_accuracy: 0.7863 - val_loss: 0.6386\n",
            "Epoch 81/100\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 21ms/step - accuracy: 0.7564 - loss: 0.7162 - val_accuracy: 0.7694 - val_loss: 0.6867\n",
            "Epoch 82/100\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 20ms/step - accuracy: 0.7561 - loss: 0.7196 - val_accuracy: 0.7787 - val_loss: 0.6624\n",
            "Epoch 83/100\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 21ms/step - accuracy: 0.7597 - loss: 0.7160 - val_accuracy: 0.7826 - val_loss: 0.6542\n",
            "Epoch 84/100\n",
            "\u001b[1m1350/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - accuracy: 0.7537 - loss: 0.7221"
          ]
        }
      ],
      "source": [
        "history = None  # For recording the history of trainning process.\n",
        "if not data_augmentation:\n",
        "    print('Not using data augmentation.')\n",
        "    history = model.fit(x_train, y_train,\n",
        "              batch_size=batch_size,\n",
        "              epochs=epochs,\n",
        "              validation_data=(x_test, y_test),\n",
        "              shuffle=True)\n",
        "else:\n",
        "    print('Using real-time data augmentation.')\n",
        "    # This will do preprocessing and realtime data augmentation:\n",
        "    datagen = ImageDataGenerator(\n",
        "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
        "        samplewise_center=False,  # set each sample mean to 0\n",
        "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
        "        samplewise_std_normalization=False,  # divide each input by its std\n",
        "        zca_whitening=False,  # apply ZCA whitening\n",
        "        zca_epsilon=1e-06,  # epsilon for ZCA whitening\n",
        "        rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n",
        "        # randomly shift images horizontally (fraction of total width)\n",
        "        width_shift_range=0.1,\n",
        "        # randomly shift images vertically (fraction of total height)\n",
        "        height_shift_range=0.1,\n",
        "        shear_range=0.,  # set range for random shear\n",
        "        zoom_range=0.,  # set range for random zoom\n",
        "        channel_shift_range=0.,  # set range for random channel shifts\n",
        "        # set mode for filling points outside the input boundaries\n",
        "        fill_mode='nearest',\n",
        "        cval=0.,  # value used for fill_mode = \"constant\"\n",
        "        horizontal_flip=True,  # randomly flip images\n",
        "        vertical_flip=False,  # randomly flip images\n",
        "        # set rescaling factor (applied before any other transformation)\n",
        "        rescale=None,\n",
        "        # set function that will be applied on each input\n",
        "        preprocessing_function=None,\n",
        "        # image data format, either \"channels_first\" or \"channels_last\"\n",
        "        data_format=None,\n",
        "        # fraction of images reserved for validation (strictly between 0 and 1)\n",
        "        validation_split=0.0)\n",
        "\n",
        "    # Compute quantities required for feature-wise normalization\n",
        "    # (std, mean, and principal components if ZCA whitening is applied).\n",
        "    datagen.fit(x_train)\n",
        "\n",
        "    # Fit the model on the batches generated by datagen.flow().\n",
        "    history = model.fit(datagen.flow(x_train, y_train,\n",
        "                                batch_size=batch_size),\n",
        "                                epochs=epochs,\n",
        "                                validation_data=(x_test, y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Heiv7tSiPMVg"
      },
      "outputs": [],
      "source": [
        "def plotmodelhistory(history):\n",
        "    fig, axs = plt.subplots(1,2,figsize=(15,5))\n",
        "    # summarize history for accuracy\n",
        "    axs[0].plot(history.history['accuracy'])\n",
        "    axs[0].plot(history.history['val_accuracy'])\n",
        "    axs[0].set_title('Model Accuracy')\n",
        "    axs[0].set_ylabel('Accuracy')\n",
        "    axs[0].set_xlabel('Epoch')\n",
        "    axs[0].legend(['train', 'validate'], loc='upper left')\n",
        "    # summarize history for loss\n",
        "    axs[1].plot(history.history['loss'])\n",
        "    axs[1].plot(history.history['val_loss'])\n",
        "    axs[1].set_title('Model Loss')\n",
        "    axs[1].set_ylabel('Loss')\n",
        "    axs[1].set_xlabel('Epoch')\n",
        "    axs[1].legend(['train', 'validate'], loc='upper left')\n",
        "    plt.show()\n",
        "\n",
        "# list all data in history\n",
        "print(history.history.keys())\n",
        "\n",
        "plotmodelhistory(history)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4owkhnkiPUj1"
      },
      "outputs": [],
      "source": [
        "# Score trained model.\n",
        "scores = model.evaluate(x_test, y_test, verbose=1)\n",
        "print('Test loss:', scores[0])\n",
        "print('Test accuracy:', scores[1])\n",
        "\n",
        "# make prediction.\n",
        "pred = model.predict(x_test)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}